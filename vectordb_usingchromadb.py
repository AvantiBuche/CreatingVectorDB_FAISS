# -*- coding: utf-8 -*-
"""VectorDB_usingChromaDB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YM4aMbLEz65aDtapYm5LguqDS416yEyM
"""

!pip install chromadb

!pip install pypdf

import pandas as pd
import numpy as np
from pypdf import PdfReader

# Define the path to your PDF file
path = "/content/sample_data/Foundations_of_Machine_Learning.pdf"

#extract text from pdf
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PdfReader(file)
        for page in reader.pages:
            text += page.extract_text() or "" # Use or "" to handle pages with no extractable text
    return text

docs = extract_text_from_pdf(path)

import chromadb
from sentence_transformers import SentenceTransformer
from chromadb.utils import embedding_functions
import uuid

# Initialize Chroma
client = chromadb.Client()
collection = client.get_or_create_collection("huge_doc_collection")

model = SentenceTransformer("all-MiniLM-L6-v2")

# Simple chunking
chunk_size = 200
chunks = [docs[i:i+chunk_size]
          for i in range(0, len(docs), chunk_size)]

print("Total chunks:", len(chunks))

# Create structured IDs
document_name = "ml_policy_doc"

ids = [f"{document_name}_{i}" for i in range(len(chunks))]

# Generate embeddings
embeddings = model.encode(chunks)

# Add to Chroma
collection.add(
    documents=chunks,
    embeddings=embeddings.tolist(),
    ids=ids,
    metadatas=[{"source": document_name}] * len(chunks)
)

print("Total vectors stored:", collection.count())

# Query Search
query = "what is machine learning"
query_embedding = model.encode([query]).tolist()

results = collection.query(
    query_embeddings=query_embedding,
    n_results=5
)

print("\nTop Results:")
for doc in results["documents"][0]:
    print("-", doc)

