# -*- coding: utf-8 -*-
"""FAISS_VectorDB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zofgrqydj3CaRDYqogsFgOUpcnpO7iF5
"""

!pip install faiss-cpu sentence-transformers

!pip install pypdf

import pandas as pd
import numpy as np
from pypdf import PdfReader

# Define the path to your PDF file
path = "/content/sample_data/Foundations_of_Machine_Learning.pdf"

#extract text from pdf
def extract_text_from_pdf(pdf_path):
    text = ""
    with open(pdf_path, 'rb') as file:
        reader = PdfReader(file)
        for page in reader.pages:
            text += page.extract_text() or "" # Use or "" to handle pages with no extractable text
    return text

pdf_text = extract_text_from_pdf(path)

pdf_text

#chunk paragraps to sentences using nltk
import nltk
nltk.download('punkt_tab')
from nltk.tokenize import sent_tokenize

sentences = sent_tokenize(pdf_text)

# Convert text to vectors / Generate embedding
# Load embedding model
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

embeddings = model.encode(sentences)
print(embeddings.shape)   # (4(rows), 384)

#create vector database using faiss
import faiss

dimension = embeddings.shape[1]
# Create index
index = faiss.IndexFlatL2(dimension)

# Add vectors
index.add(np.array(embeddings))

print("Total vectors stored:", index.ntotal)

# Perform similar search

query = "What is a machine learning?"
query_vector = model.encode([query])

# Search top 10 similar results
k = 10
distances, indices = index.search(np.array(query_vector), k)

print("Most similar documents:")
for idx in indices[0]:
    print(sentences[idx])

query2 = "What is analysis"
query_vector2 = model.encode([query2])

# Search top 10 similar results
k = 10
distances, indices = index.search(np.array(query_vector2), k)

print("Most similar documents:")
for idx in indices[0]:
    print(sentences[idx])

